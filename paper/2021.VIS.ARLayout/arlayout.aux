\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Zhu2020}
\citation{Huang2014,Reipschlager2021}
\citation{Chen2020}
\citation{Chen2020}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{}{1}{}{Doc-Start}{}}
\citation{Liu2019,Liu2021a}
\citation{Willett2017}
\citation{Butscher2018}
\citation{ElSayed2015}
\citation{Herr2017}
\citation{Evans2017}
\citation{MarderEppstein2016}
\citation{Keselman2017}
\citation{Amin2015}
\citation{Wagner2003,Hirokazu2002}
\citation{Cushnan2013}
\citation{ArCore}
\citation{Liberty2018}
\citation{aframe}
\citation{webvr}
\citation{Davison2003}
\citation{Davison2007}
\citation{Davison2007}
\citation{Jones2011}
\citation{Leutenegger2015}
\citation{Lee2012}
\citation{Carrera2018}
\citation{Geroimenko2012}
\citation{Reipschlager2021}
\citation{Huang2014}
\citation{Pousman2007}
\citation{Danziger2008}
\citation{Fogg1998}
\citation{Li2010,Li2010a}
\citation{Chiu2009,Kim2010,Kjeldskov2012}
\citation{Jansen2015}
\citation{Jansen2013,Jansen2015a}
\citation{Khot2014}
\citation{Stusak2014}
\citation{Huang2016}
\citation{Stusak2014}
\citation{Goh2016}
\citation{Monigatti2010}
\citation{Allen1999,Mamassian1998,Yonas1978}
\citation{Tsuda2006,Wither2005}
\citation{Bichlmeier2007,Furmanski2002}
\citation{Mendez2009}
\citation{Chen2020}
\citation{Sicat2019}
\citation{Cordeil2019}
\citation{Chen2020a}
\citation{WIMPUI}
\citation{Ren2014}
\citation{Wongsuphasawat2016}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  The task illustrations on searching (a), re-grouping (b), and re-ranking (c) in AR environment. We take the library/bookstore scenario as an example. \relax }}{2}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:intro_relayout_task}{{1}{2}{The task illustrations on searching (a), re-grouping (b), and re-ranking (c) in AR environment. We take the library/bookstore scenario as an example. \relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}AR Visualizations}{2}{subsection.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Personal Visualization}{2}{subsection.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Visualization Authoring Tools}{2}{subsection.7}\protected@file@percent }
\citation{Shreiner2013}
\citation{Parisi2012}
\citation{Li2018}
\citation{Zhu2013}
\citation{Satyanarayan2017}
\citation{Pedretti2002}
\citation{Sicat2019}
\citation{Rhee2020}
\citation{ElSayed2015}
\citation{Lee2021a}
\citation{Lee2021}
\citation{Chen2020a}
\citation{Chen2020}
\citation{Sicat2019}
\citation{Rhee2020}
\citation{ElSayed2015}
\citation{Lee2021a}
\citation{Lee2021}
\citation{Chen2020a}
\citation{Chen2020}
\citation{Chen2020,Chen2020a}
\citation{Chen2020}
\citation{Chen2020}
\citation{Chen2020a}
\citation{ElSayed2015}
\citation{Chen2020a}
\citation{Chen2020}
\citation{Sicat2019,Rhee2020,Lee2021}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Comparison to the most related recent work about authoring PV tools towards AR or VR visualizations. The most related approaches include: DXR\nobreakspace  {}\cite  {Sicat2019}, Augmented Virtual Teleportation (AVT)\nobreakspace  {}\cite  {Rhee2020}, Situated Analytics (SA Vis)\nobreakspace  {}\cite  {ElSayed2015}, Data Visceralization (VR Visc)\nobreakspace  {}\cite  {Lee2021a}, Shared Surfaces and Spaces (VR Collab Vis)\nobreakspace  {}\cite  {Lee2021}, PapARVis\nobreakspace  {}\cite  {Chen2020a}, MARVisT\nobreakspace  {}\cite  {Chen2020}. The workflow can be categorized into PV (single user in a personal context), single user or collaborative users. \relax }}{3}{table.caption.8}\protected@file@percent }
\newlabel{tab:discussion_relatedwork_cmp}{{1}{3}{Comparison to the most related recent work about authoring PV tools towards AR or VR visualizations. The most related approaches include: DXR~\cite {Sicat2019}, Augmented Virtual Teleportation (AVT)~\cite {Rhee2020}, Situated Analytics (SA Vis)~\cite {ElSayed2015}, Data Visceralization (VR Visc)~\cite {Lee2021a}, Shared Surfaces and Spaces (VR Collab Vis)~\cite {Lee2021}, PapARVis~\cite {Chen2020a}, MARVisT~\cite {Chen2020}. The workflow can be categorized into PV (single user in a personal context), single user or collaborative users. \relax }{table.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Relationship with The Most Related Work}{3}{subsection.9}\protected@file@percent }
\newlabel{sec:relatedworkcomparison}{{2.4}{3}{Relationship with The Most Related Work}{subsection.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Design Rationale}{3}{section.10}\protected@file@percent }
\newlabel{sec:design}{{3}{3}{Design Rationale}{section.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Design Goals}{3}{subsection.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Design Considerations and Design Details}{3}{subsection.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  The structural design of ARLayout, including simplified data processing, data transmission, and data presentation process. \relax }}{4}{figure.caption.13}\protected@file@percent }
\newlabel{fig:design_overview}{{2}{4}{The structural design of ARLayout, including simplified data processing, data transmission, and data presentation process. \relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Design Details: System Workflow Design}{4}{subsection.14}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Evaluations}{4}{section.15}\protected@file@percent }
\newlabel{sec:evaluation}{{4}{4}{Evaluations}{section.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Case Scenarios}{4}{subsection.16}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Building re-layouts with different methods in three scenarios (library, coffee shop and eyeshadow). Targets in different scenarios have different kinds of attributes. \relax }}{4}{figure.caption.17}\protected@file@percent }
\newlabel{fig:design_compare}{{3}{4}{Building re-layouts with different methods in three scenarios (library, coffee shop and eyeshadow). Targets in different scenarios have different kinds of attributes. \relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Pre-study result: Most of participants have experienced these scenarios in their life and require assistance to better obtain and organize information. \relax }}{4}{figure.caption.18}\protected@file@percent }
\newlabel{fig:pre_study}{{4}{4}{Pre-study result: Most of participants have experienced these scenarios in their life and require assistance to better obtain and organize information. \relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Tasks}{4}{subsection.19}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  Post-study result: most of participants react positively to \textit  {ARLayout}. \relax }}{5}{figure.caption.20}\protected@file@percent }
\newlabel{fig:evaluation_result}{{5}{5}{Post-study result: most of participants react positively to \textit {ARLayout}. \relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}User Study}{5}{subsection.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}User Study Results}{5}{subsection.22}\protected@file@percent }
\citation{Mcauley2015,He2016}
\citation{Ling2018}
\citation{Zhu2020}
\citation{Liu2019,Liu2021a}
\citation{Chen2018}
\citation{ARKit}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  The books in (a) is slanted, so the OCR module is checked for direction and corrected before it is actually called. The final result is figure (b). (c) and (d) show the difference in the arrangement of text between Chinese and English books. Artistic fonts exist in (e). (f) and (g) define the reference regions required for a custom template. Reference Fields are identified in (f) and Identification Areas are identified in (g). \relax }}{6}{figure.caption.23}\protected@file@percent }
\newlabel{fig:implementation_ocr}{{6}{6}{The books in (a) is slanted, so the OCR module is checked for direction and corrected before it is actually called. The final result is figure (b). (c) and (d) show the difference in the arrangement of text between Chinese and English books. Artistic fonts exist in (e). (f) and (g) define the reference regions required for a custom template. Reference Fields are identified in (f) and Identification Areas are identified in (g). \relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Implementation and Performance}{6}{section.25}\protected@file@percent }
\newlabel{sec:implementation}{{5}{6}{Implementation and Performance}{section.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Database}{6}{subsection.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Optical Character Recognition}{6}{subsection.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Image Segmentation and Labelling}{6}{subsection.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Coordinates Consistency between Virtuality and Reality}{6}{subsection.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Small Multiples and Virtual Models}{6}{subsection.31}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Usage Scenarios}{6}{section.36}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Library/Bookstore Scenario}{6}{subsection.37}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  The network illustration about how PaddleSeg is integrated into \textit  {ARLayout}. We take DeepLab as an example, one of the key modules of PaddleSeg. The encoder module encodes multi-scale contextual information by applying atrous convolution at multiple scales, while the simple yet effective decoder module refines the segmentation results along object boundaries. \relax }}{7}{figure.caption.24}\protected@file@percent }
\newlabel{fig:implementation_network_deeplab}{{7}{7}{The network illustration about how PaddleSeg is integrated into \textit {ARLayout}. We take DeepLab as an example, one of the key modules of PaddleSeg. The encoder module encodes multi-scale contextual information by applying atrous convolution at multiple scales, while the simple yet effective decoder module refines the segmentation results along object boundaries. \relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  (a) shows a mobile device is scanning the bookshelves. (b) is the top view of (a) showing the horizontal view angle $\alpha $, where $d$ is the distance between the mobile device and the target books estimated by \textit  {ARLayout}, and $x$ is the number of pixels horizontally. (c) shows a segmented book sample with the extracted position and size. (d) there are five blocks with recognized coffee names on a coffee menu. \relax }}{8}{figure.caption.26}\protected@file@percent }
\newlabel{fig:implementation_front}{{8}{8}{(a) shows a mobile device is scanning the bookshelves. (b) is the top view of (a) showing the horizontal view angle $\alpha $, where $d$ is the distance between the mobile device and the target books estimated by \textit {ARLayout}, and $x$ is the number of pixels horizontally. (c) shows a segmented book sample with the extracted position and size. (d) there are five blocks with recognized coffee names on a coffee menu. \relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Coffee Shop Scenario}{8}{subsection.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Eyeshadow Scenario}{8}{subsection.39}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion and Future Work}{8}{section.40}\protected@file@percent }
\newlabel{sec:discussion}{{7}{8}{Discussion and Future Work}{section.40}{}}
\citation{Zhang2017}
\citation{Liu2019,Liu2021a}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  The user builds re-layouts and find books in a library. (a): The user scans the original bookshelves, 778 books recognized. (b): \textit  {ARLayout} visualize the remaining books after fuzzy searching ``econimic''. (c): The user chooses to re-group by publisher, and searches ``Chicago''. Books from ``University of Chicago Press'' and other presses are placed on different layers. The user browses those books with fisheye effect. (d): The user searches ``social'' in books' names, several books are highlighted in red. (e): The user re-ranks those books by ratings. Books sorted in descending order are placed from the left to the right. (f): The user selects several candidate books, they are moved to a layer below. (g): \textit  {ARLayout} shows books' word clouds. (h): The user compares books' ratings and prices via bar chart. (i): The user restores books to their original layout, and searches a book's name. The target book is highlighted in red. (j): The user finds and picks the target book according to its loation on the screen. \relax }}{9}{figure.caption.32}\protected@file@percent }
\newlabel{fig:casestudy_book}{{9}{9}{The user builds re-layouts and find books in a library. (a): The user scans the original bookshelves, 778 books recognized. (b): \textit {ARLayout} visualize the remaining books after fuzzy searching ``econimic''. (c): The user chooses to re-group by publisher, and searches ``Chicago''. Books from ``University of Chicago Press'' and other presses are placed on different layers. The user browses those books with fisheye effect. (d): The user searches ``social'' in books' names, several books are highlighted in red. (e): The user re-ranks those books by ratings. Books sorted in descending order are placed from the left to the right. (f): The user selects several candidate books, they are moved to a layer below. (g): \textit {ARLayout} shows books' word clouds. (h): The user compares books' ratings and prices via bar chart. (i): The user restores books to their original layout, and searches a book's name. The target book is highlighted in red. (j): The user finds and picks the target book according to its loation on the screen. \relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{9}{section.41}\protected@file@percent }
\bibstyle{abbrv-doi}
\bibdata{arlayout}
\bibcite{aframe}{1}
\bibcite{webvr}{2}
\bibcite{WIMPUI}{3}
\bibcite{ARKit}{4}
\bibcite{ArCore}{5}
\bibcite{Yonas1978}{6}
\bibcite{Amin2015}{7}
\bibcite{Butscher2018}{8}
\bibcite{Carrera2018}{9}
\bibcite{Chen2020}{10}
\bibcite{Chen2020a}{11}
\bibcite{Chiu2009}{12}
\bibcite{Furmanski2002}{13}
\bibcite{Bichlmeier2007}{14}
\bibcite{Cordeil2019}{15}
\bibcite{Cushnan2013}{16}
\bibcite{Mendez2009}{17}
\bibcite{Evans2017}{18}
\bibcite{Fogg1998}{19}
\bibcite{Geroimenko2012}{20}
\bibcite{Goh2016}{21}
\bibcite{Herr2017}{22}
\bibcite{Huang2016}{23}
\bibcite{Huang2014}{24}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces  The user buinds re-layouts for a coffee menu. (a): The user scans the coffee menu(b): The user search ``espresso''. Three related coffees are highlighted.(c): The user browses the menu with fisheye. The focused coffee will be magnified, with its summary shown besides it. (d): The user re-groupps all the drinks by sugar. (e): The user selects four candidate coffees. They are moved to the right side of the menu(f): The user compares candidate coffees by their ingredients graphs in small multiples. (g): The user re-groupps drinks by fat. (h): The user re-ranks drinks by calories. Drinks with more calories are moved to the left side. (i): The user compares the word cloud of the candidate coffees. (j): The user browses drinks on the right side of the menu to choose one with less calories. \relax }}{10}{figure.caption.33}\protected@file@percent }
\newlabel{fig:casestudy_coffee}{{10}{10}{The user buinds re-layouts for a coffee menu. (a): The user scans the coffee menu(b): The user search ``espresso''. Three related coffees are highlighted.(c): The user browses the menu with fisheye. The focused coffee will be magnified, with its summary shown besides it. (d): The user re-groupps all the drinks by sugar. (e): The user selects four candidate coffees. They are moved to the right side of the menu(f): The user compares candidate coffees by their ingredients graphs in small multiples. (g): The user re-groupps drinks by fat. (h): The user re-ranks drinks by calories. Drinks with more calories are moved to the left side. (i): The user compares the word cloud of the candidate coffees. (j): The user browses drinks on the right side of the menu to choose one with less calories. \relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces  (a): The orignial poster hanging on the wall outside a coffee shop. (b): The user browses coffees' details with fisheye effect. (c): The user re-groups drinks by fat content intervals. (d): The user re-ranks drinks by calorie content. \relax }}{10}{figure.caption.34}\protected@file@percent }
\newlabel{fig:casestudy_coffee_poster}{{11}{10}{(a): The orignial poster hanging on the wall outside a coffee shop. (b): The user browses coffees' details with fisheye effect. (c): The user re-groups drinks by fat content intervals. (d): The user re-ranks drinks by calorie content. \relax }{figure.caption.34}{}}
\bibcite{Li2010}{25}
\bibcite{Li2010a}{26}
\bibcite{Davison2003}{27}
\bibcite{Davison2007}{28}
\bibcite{Danziger2008}{29}
\bibcite{Kjeldskov2012}{30}
\bibcite{Jansen2015}{31}
\bibcite{Jansen2013}{32}
\bibcite{Jansen2015a}{33}
\bibcite{Wither2005}{34}
\bibcite{Hirokazu2002}{35}
\bibcite{Keselman2017}{36}
\bibcite{Khot2014}{37}
\bibcite{Lee2021a}{38}
\bibcite{Lee2021}{39}
\bibcite{Lee2012}{40}
\bibcite{Leutenegger2015}{41}
\bibcite{Li2018}{42}
\bibcite{Liberty2018}{43}
\bibcite{Ling2018}{44}
\bibcite{Liu2019}{45}
\bibcite{Liu2021a}{46}
\bibcite{MarderEppstein2016}{47}
\bibcite{Mcauley2015}{48}
\bibcite{Monigatti2010}{49}
\bibcite{Allen1999}{50}
\bibcite{Parisi2012}{51}
\bibcite{Mamassian1998}{52}
\bibcite{Pedretti2002}{53}
\bibcite{Pousman2007}{54}
\bibcite{Reipschlager2021}{55}
\bibcite{Ren2014}{56}
\bibcite{Rhee2020}{57}
\bibcite{Jones2011}{58}
\bibcite{Satyanarayan2017}{59}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces  The user builds re-layouts for eyeshadows. (a): The user scans the various eyeshadows displayed on a cosmetics shop's desk. (b): The user re-groupps those eyeshadows by eyetypes, and views certain eyeshadow's details as well as a graph showing places to apply it on. (c): The user views the candidate eyeshadow's 3-D virtual makeup try-on. (d): The user re-groupps eyeshadows by high-rated scheme. Different schemes have features like ``Deep Blue'' or ``Soft Smokey''. (e): The user searches ``Scheme 13'' in their original layout, eyeshaodws contained in this scheme are highlighted. \relax }}{11}{figure.caption.35}\protected@file@percent }
\newlabel{fig:casestudy_eye}{{12}{11}{The user builds re-layouts for eyeshadows. (a): The user scans the various eyeshadows displayed on a cosmetics shop's desk. (b): The user re-groupps those eyeshadows by eyetypes, and views certain eyeshadow's details as well as a graph showing places to apply it on. (c): The user views the candidate eyeshadow's 3-D virtual makeup try-on. (d): The user re-groupps eyeshadows by high-rated scheme. Different schemes have features like ``Deep Blue'' or ``Soft Smokey''. (e): The user searches ``Scheme 13'' in their original layout, eyeshaodws contained in this scheme are highlighted. \relax }{figure.caption.35}{}}
\bibcite{Shreiner2013}{60}
\bibcite{Sicat2019}{61}
\bibcite{Stusak2014}{62}
\bibcite{Kim2010}{63}
\bibcite{Tsuda2006}{64}
\bibcite{Wagner2003}{65}
\bibcite{Willett2017}{66}
\bibcite{Wongsuphasawat2016}{67}
\bibcite{Zhang2017}{68}
\bibcite{Zhu2013}{69}
\bibcite{Zhu2020}{70}
